{
  "version": "1",
  "metadata": {
    "marimo_version": "0.17.7"
  },
  "cells": [
    {
      "id": "kXkF",
      "code_hash": "fca4585c87d2e2e3947108c0cd4b91b6",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "EpKr",
      "code_hash": "6e3af912bab431baab8dd6ed5247e6e7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"_1\">\u30e2\u30c7\u30eb\u3092\u30ed\u30fc\u30c9\u3059\u308b</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "svpB",
      "code_hash": "0b209c4be03bc43a2af20f88f42b1c01",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<pre style='font-size: 12px'>XLMRobertaModel(\n  (embeddings): XLMRobertaEmbeddings(\n    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n    (position_embeddings): Embedding(514, 768, padding_idx=1)\n    (token_type_embeddings): Embedding(1, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): XLMRobertaEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x XLMRobertaLayer(\n        (attention): XLMRobertaAttention(\n          (self): XLMRobertaSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): XLMRobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): XLMRobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): XLMRobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): XLMRobertaPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)</pre>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "iIwq",
      "code_hash": "9bab9716e5f20e81e39f0fc1be0b55d8",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<pre style='font-size: 12px'>XLMRobertaConfig {\n  &quot;architectures&quot;: [\n    &quot;XLMRobertaForMaskedLM&quot;\n  ],\n  &quot;attention_probs_dropout_prob&quot;: 0.1,\n  &quot;bos_token_id&quot;: 0,\n  &quot;classifier_dropout&quot;: null,\n  &quot;dtype&quot;: &quot;float32&quot;,\n  &quot;eos_token_id&quot;: 2,\n  &quot;hidden_act&quot;: &quot;gelu&quot;,\n  &quot;hidden_dropout_prob&quot;: 0.1,\n  &quot;hidden_size&quot;: 768,\n  &quot;initializer_range&quot;: 0.02,\n  &quot;intermediate_size&quot;: 3072,\n  &quot;layer_norm_eps&quot;: 1e-05,\n  &quot;max_position_embeddings&quot;: 514,\n  &quot;model_type&quot;: &quot;xlm-roberta&quot;,\n  &quot;num_attention_heads&quot;: 12,\n  &quot;num_hidden_layers&quot;: 12,\n  &quot;output_past&quot;: true,\n  &quot;pad_token_id&quot;: 1,\n  &quot;position_embedding_type&quot;: &quot;absolute&quot;,\n  &quot;transformers_version&quot;: &quot;4.57.1&quot;,\n  &quot;type_vocab_size&quot;: 1,\n  &quot;use_cache&quot;: true,\n  &quot;vocab_size&quot;: 250002\n}\n</pre>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Hbol",
      "code_hash": "e0a82cdcf576cd2410eaa404295040f1",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"_1\">\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u3066\u307f\u308b</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "eKSj",
      "code_hash": "b772edffce9cf16d21634a8a804c8a8f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<pre style='font-size: 12px'>{&#x27;input_ids&#x27;: tensor([[     0,      6, 140730,  26397,   2996,  23731, 206030,  58689,     37,\n          34933, 110175,  99889,  14956,  60486,  10449,  21512, 218192,   6787,\n             30,      2]]), &#x27;attention_mask&#x27;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}</pre>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "LTao",
      "code_hash": "eeff2cc40fe46b97ac6b638454e44a74",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"model-head\">Model Head\u306a\u3057\u3067\u547c\u3073\u51fa\u3059</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "VjHl",
      "code_hash": "5a94a84a8b42079821d58e8682dbe104",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<pre style='font-size: 12px'>BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1101,  0.1004,  0.1236,  ..., -0.1174,  0.1644, -0.0008],\n         [-0.0236, -0.0402, -0.0200,  ...,  0.2609,  0.1313, -0.0166],\n         [-0.0069, -0.1003,  0.0329,  ..., -0.0614,  0.0616, -0.0735],\n         ...,\n         [ 0.0940, -0.0113,  0.0026,  ...,  0.2091,  0.0921,  0.0684],\n         [ 0.0360, -0.0316,  0.0127,  ...,  0.0166,  0.1308,  0.0913],\n         [ 0.1085,  0.0875,  0.0416,  ..., -0.2670,  0.0664,  0.0725]]],\n       grad_fn=&lt;NativeLayerNormBackward0&gt;), pooler_output=tensor([[-5.2021e-02,  2.2002e-01,  6.6936e-02,  5.3671e-01,  5.4200e-02,\n          3.7260e-01,  3.9080e-01, -3.4678e-01,  2.0919e-01, -9.8379e-02,\n         -7.1416e-02,  2.0774e-01,  3.3789e-01,  3.7534e-01, -3.7111e-01,\n         -1.8270e-01,  3.6955e-01,  3.4811e-01,  9.5930e-03, -2.2268e-01,\n         -4.2933e-01,  4.6118e-01, -7.0625e-01, -5.7989e-01, -2.8854e-01,\n          6.0186e-01,  1.0740e-01, -2.6558e-01, -1.2478e-01,  6.8823e-01,\n          2.0628e-01,  4.5637e-01, -2.5228e-01, -1.6067e-02,  1.7080e-01,\n         -1.1642e-01,  3.8703e-01,  2.1450e-01,  5.0942e-01,  3.5209e-01,\n          1.0027e-01, -1.2929e-01, -1.8067e-01,  1.0056e-01,  3.3056e-01,\n         -2.3114e-01,  2.9187e-01,  1.8625e-02, -2.0906e-01,  4.3569e-01,\n          6.1946e-01, -1.3817e-01, -7.2512e-02,  1.0330e-01,  1.8536e-01,\n          8.4558e-02,  3.5100e-01, -3.4492e-01, -1.7816e-01, -5.7799e-01,\n         -4.1113e-02,  6.3173e-01,  4.3862e-01,  2.8970e-01,  3.4376e-01,\n         -5.4869e-01,  5.4726e-02, -8.8062e-02, -6.2863e-01,  1.9131e-01,\n          3.8203e-02, -3.6650e-01,  3.8068e-01,  5.0226e-02,  2.0149e-01,\n          8.2771e-03,  3.5547e-01,  1.5808e-01,  4.0153e-01,  2.8237e-01,\n          2.6540e-01, -3.0446e-01,  1.2530e-01, -2.1750e-01,  1.3359e-01,\n          6.3242e-01, -4.5828e-01,  7.8162e-01,  3.4824e-01,  2.0853e-01,\n         -1.8979e-01,  2.9366e-02, -2.9902e-01,  2.7456e-01, -4.2934e-01,\n          2.7947e-01, -2.6752e-01, -5.9045e-01,  3.9516e-03, -5.3869e-02,\n         -3.7615e-01, -3.1801e-01,  2.5202e-01, -4.7712e-01, -1.4067e-01,\n         -7.5602e-01,  5.2651e-01,  4.8327e-01, -2.0581e-01,  3.8788e-01,\n          1.9087e-01,  1.6038e-01,  3.3430e-01, -6.4820e-01,  2.0316e-01,\n          3.3979e-01,  5.4849e-01,  5.8633e-02, -4.8833e-02, -2.4548e-01,\n         -2.3181e-01,  5.7887e-01, -2.7166e-01, -1.4116e-01,  3.6661e-01,\n          1.8499e-01, -1.8325e-01,  6.4196e-01,  3.1113e-01,  4.3068e-02,\n          4.4762e-01, -3.3489e-01,  3.4009e-01, -6.1326e-01, -1.5997e-02,\n         -2.6394e-01,  4.5997e-01, -3.7063e-01,  3.2743e-02, -5.5323e-01,\n          4.0449e-01, -4.5987e-02, -1.8601e-01,  3.3449e-01, -1.5835e-01,\n          4.9853e-01,  4.5565e-01,  9.1574e-02, -2.7949e-01,  7.9437e-02,\n          5.9646e-01, -3.7174e-01,  1.7081e-01, -2.1925e-01,  9.9415e-02,\n          4.8345e-01, -4.2739e-02,  3.0353e-01, -2.3543e-01,  2.9135e-01,\n         -1.2774e-01,  2.8517e-01, -2.1578e-01, -3.2651e-01, -5.0479e-01,\n          1.9172e-01,  2.0239e-01,  6.8341e-01, -1.0724e-01,  1.5894e-01,\n         -2.7666e-01,  1.2470e-01,  5.1404e-01, -1.1541e-01, -1.6425e-01,\n         -5.8439e-01, -1.1949e-01, -3.0445e-01,  3.1903e-01, -9.7321e-02,\n         -2.9661e-01, -3.4953e-01,  7.0270e-01,  3.3250e-01, -2.9548e-01,\n          7.8723e-02, -2.8111e-01, -3.7864e-01, -2.5841e-02, -2.1198e-01,\n         -3.3914e-01, -1.3814e-01,  2.2609e-01, -5.9474e-01, -2.1176e-01,\n         -3.7368e-01, -1.0583e-01, -1.8735e-01, -4.0774e-01,  4.5020e-01,\n          3.4795e-01,  7.9175e-02, -3.6842e-01, -2.7942e-01,  6.1540e-02,\n          1.9043e-02, -2.7147e-01,  3.7149e-01, -8.0954e-02,  2.2306e-01,\n          2.3596e-02,  2.9267e-01, -4.2489e-02, -6.6587e-01, -4.1954e-01,\n          2.1274e-01, -7.3345e-01,  3.9237e-01, -2.6717e-01,  2.6420e-01,\n         -5.3242e-01,  4.0210e-01, -4.1657e-02, -5.0853e-01,  4.1219e-01,\n          5.5968e-01,  6.0863e-01, -5.6442e-01,  1.8297e-01, -2.3598e-02,\n          6.4773e-01, -3.2293e-02, -1.5154e-01, -8.3134e-02,  1.9843e-02,\n         -4.4860e-01,  3.7275e-01,  3.8939e-01, -4.7371e-01,  5.7508e-01,\n         -2.9539e-01,  1.6560e-01,  3.2455e-01,  9.0843e-02,  7.3692e-02,\n         -3.7815e-01,  3.8042e-01, -4.7419e-01,  2.8054e-01,  3.2483e-02,\n         -7.2313e-01, -2.4816e-01,  9.4167e-02,  6.6422e-01, -4.0291e-01,\n         -4.0095e-01, -1.2374e-02,  4.5336e-01, -5.1239e-01, -1.5273e-01,\n          2.7970e-02,  6.8509e-02, -4.2404e-02, -5.9302e-01, -4.6871e-01,\n          1.0921e-01, -6.3633e-02,  9.2801e-02, -2.1355e-01, -1.3752e-01,\n          4.3600e-01,  2.2000e-02,  2.8491e-01, -8.4813e-04, -3.7101e-01,\n          1.7502e-03,  1.0042e-01, -5.5614e-01,  2.5411e-01,  1.7552e-01,\n          7.4915e-01, -3.3577e-01,  3.7520e-01, -2.9625e-01,  1.7618e-01,\n         -9.1521e-04,  4.4638e-01,  1.3464e-01, -1.9083e-01,  4.5893e-01,\n         -5.2948e-01, -1.7149e-01,  1.5689e-01,  1.7196e-01, -3.3673e-01,\n          2.9796e-01, -1.9940e-01, -7.5582e-01,  2.2435e-01, -1.5252e-01,\n         -7.3818e-01, -7.6373e-01, -3.8963e-01, -2.7841e-01,  5.5123e-01,\n          2.9422e-01, -5.3786e-01, -3.8807e-02, -1.3347e-01,  4.8766e-02,\n          4.5682e-01,  2.7581e-01,  1.4561e-01,  1.0436e-01, -5.5192e-01,\n          3.1458e-01, -5.2490e-01, -2.3240e-02, -1.8672e-01,  2.6786e-01,\n          2.0177e-01,  9.1764e-02,  7.5859e-02,  6.7615e-01,  2.9447e-02,\n         -1.8435e-01, -3.9661e-01, -1.0302e-01, -5.6720e-02,  2.4987e-02,\n          4.1317e-01, -3.8440e-02, -4.5969e-01, -2.8319e-01,  1.0609e-01,\n          1.9140e-01,  5.2844e-01,  2.9125e-01, -2.8760e-01, -6.1301e-02,\n         -8.0285e-02, -4.9814e-01, -5.2366e-01,  3.2226e-01, -5.5172e-01,\n         -4.3980e-01,  2.0794e-01,  4.6765e-02, -4.1326e-01, -8.4869e-02,\n         -4.8167e-01,  4.8061e-01, -5.9374e-02, -4.3565e-01, -1.4962e-01,\n          2.1609e-01,  5.7524e-01,  3.2314e-03,  1.7540e-01,  1.6390e-01,\n          7.0800e-02, -1.0914e-02,  2.7035e-01,  5.3768e-02,  1.8077e-01,\n         -6.0840e-01, -5.5955e-02, -2.8093e-01,  6.0120e-01,  4.5242e-02,\n          5.0023e-02,  1.0612e-01,  1.2209e-01, -3.1276e-01,  2.6170e-01,\n         -2.2594e-02, -3.0241e-01,  4.1886e-01, -1.4965e-01, -1.3371e-01,\n          4.6776e-01,  1.3732e-01, -7.9807e-02, -9.0590e-02, -1.9467e-02,\n          3.4313e-01,  5.7303e-01,  7.0067e-02,  6.0252e-01, -1.4729e-01,\n          6.0265e-01,  2.2109e-01, -2.6114e-01, -2.5255e-01,  9.1946e-02,\n         -6.1401e-01,  5.5208e-01, -4.3139e-01,  3.4495e-01, -4.3683e-02,\n         -3.6967e-01, -4.5699e-01,  6.2279e-01,  4.3795e-01,  4.1456e-01,\n          2.7353e-01,  6.6784e-02,  5.3810e-01, -6.5868e-01,  3.3988e-01,\n          3.9513e-01,  1.5270e-01,  1.3558e-01, -3.7691e-01, -1.7996e-01,\n         -1.7053e-01, -3.3311e-02, -2.2084e-01, -3.2864e-01, -1.3997e-01,\n          3.4462e-01, -5.3077e-01,  2.4689e-01,  6.9918e-01,  6.7239e-01,\n         -1.5547e-01,  1.0893e-01, -1.5368e-01, -1.7030e-01, -6.7283e-01,\n          8.4700e-02, -1.4466e-01, -4.7831e-01,  5.9508e-02, -1.2633e-01,\n         -4.8914e-01,  8.3062e-02,  1.1841e-01,  6.6560e-02,  2.0976e-02,\n         -1.8809e-01,  1.3665e-01,  4.8993e-01, -1.5750e-01, -1.6128e-01,\n         -2.1589e-01,  1.6327e-01,  3.4291e-01, -2.2905e-01,  1.5104e-01,\n          3.7729e-01, -4.1300e-01,  5.5846e-01,  1.6321e-01,  6.2041e-01,\n          3.1128e-01,  9.6729e-02,  2.0466e-01,  2.0871e-01, -3.9510e-01,\n          2.3966e-01, -3.7985e-01, -2.1736e-01,  2.9715e-03, -4.4933e-01,\n          2.6431e-01, -2.2058e-01, -7.0811e-01,  2.3892e-01,  3.9820e-01,\n         -2.0410e-01, -4.6042e-01, -4.2246e-02,  7.3539e-02, -4.8171e-01,\n         -8.8092e-02,  1.5885e-01, -1.6269e-01, -3.4184e-02,  2.2677e-01,\n          1.3802e-01, -5.5285e-02, -4.1798e-01,  3.2581e-01, -3.5676e-01,\n          6.5704e-01, -2.6983e-02,  4.0246e-02, -2.4269e-01, -4.5511e-01,\n         -1.9889e-01,  4.1711e-02,  2.0014e-01,  6.2670e-01, -1.8068e-01,\n          3.3294e-01,  2.8150e-01, -3.1632e-01, -4.5266e-01, -6.0506e-01,\n         -1.3877e-01,  1.3614e-01, -3.5583e-01,  2.0936e-01,  4.4992e-01,\n         -7.2347e-02, -1.0532e-01, -1.0142e-01,  1.1231e-01, -9.1142e-02,\n          2.9688e-01,  1.6597e-01, -6.2072e-01, -3.9593e-01, -5.2012e-02,\n         -2.8056e-01,  4.7648e-01,  3.8909e-01,  2.6517e-02,  1.7625e-01,\n          5.5336e-01, -3.2257e-01, -1.6377e-02,  1.7959e-01, -1.1172e-01,\n         -1.1578e-01, -2.4674e-01, -7.8554e-02,  4.9814e-01,  1.6423e-01,\n         -4.0317e-01, -4.6449e-01,  2.8817e-01,  2.2772e-01, -1.4193e-01,\n         -2.5062e-01,  6.6315e-01,  1.7582e-01, -1.3794e-01,  2.1270e-01,\n          4.7035e-01, -4.6542e-02,  4.1850e-01,  2.7725e-01,  7.2887e-01,\n          2.2315e-01, -1.3616e-01,  2.2213e-01, -5.3148e-01, -3.9018e-01,\n         -3.6484e-01,  6.5558e-01,  1.5597e-01,  3.9045e-01,  1.9178e-01,\n          7.6042e-02,  1.6982e-01,  2.5279e-01, -2.8787e-01, -2.2426e-01,\n          8.5268e-02,  4.2353e-01, -3.4988e-04, -3.2639e-01, -1.2496e-01,\n          4.2605e-01,  2.5185e-01, -4.4135e-01, -4.1348e-01,  4.8621e-01,\n          3.5279e-02, -6.3239e-02, -1.5641e-01,  2.5931e-01,  2.1562e-01,\n          3.4486e-01, -4.1042e-01, -4.5352e-01,  3.9562e-01, -3.6685e-01,\n         -1.1843e-01, -8.9526e-03,  7.5687e-01,  1.9432e-01, -8.5450e-02,\n          2.3298e-02, -2.9511e-02, -5.0020e-01, -4.5803e-01,  8.1636e-02,\n         -7.4455e-01,  1.6603e-01,  4.5282e-01, -1.6735e-01, -2.3169e-01,\n         -3.0216e-01,  3.2690e-02, -4.5764e-01,  2.5672e-01, -8.3185e-02,\n         -4.9074e-01,  2.3339e-01, -3.6723e-01, -1.0959e-01, -3.2632e-01,\n         -1.1260e-01,  2.6729e-01,  6.8370e-01, -4.6120e-01, -2.0653e-01,\n         -5.6362e-01,  1.7834e-01, -8.2956e-02,  8.0200e-03, -5.6203e-01,\n         -7.4314e-01, -3.1536e-02,  1.6541e-01,  6.0261e-01, -1.4295e-01,\n          1.0876e-01,  7.0537e-02,  3.2078e-02, -2.0413e-01,  7.5143e-01,\n          5.1528e-01, -2.5362e-01, -3.0482e-01, -5.6952e-01, -3.0442e-01,\n         -4.0053e-01, -2.6447e-01, -1.1425e-01, -3.7632e-01, -1.1827e-01,\n         -7.1080e-02,  7.5609e-01, -3.5848e-01, -3.4241e-01,  3.0392e-02,\n         -8.0675e-02,  1.2903e-02,  2.2189e-02,  1.6746e-02, -2.5989e-01,\n         -1.9949e-01,  2.9513e-01,  7.8734e-02, -3.6989e-02, -4.2340e-01,\n         -3.2814e-01, -5.8417e-01,  6.1223e-02,  1.3382e-01, -2.8550e-01,\n         -3.8310e-01,  5.2772e-01,  3.0353e-03,  1.3855e-01, -5.8189e-01,\n          4.4449e-01, -3.9968e-01,  2.3359e-01, -2.9335e-01, -2.2593e-02,\n         -3.5297e-01, -2.4340e-01, -1.0405e-01,  1.5683e-01, -8.2571e-02,\n          4.6187e-01, -1.4106e-01,  4.5962e-01,  9.8831e-02, -2.9874e-02,\n          1.8837e-01,  5.4975e-01,  1.2906e-01, -6.7804e-01, -1.9885e-01,\n         -7.5155e-01,  5.8335e-02, -9.8047e-03,  4.2532e-01, -6.3198e-01,\n         -4.9997e-02,  3.7554e-01,  1.0917e-02, -2.9082e-01,  3.0648e-01,\n         -3.6687e-01,  5.9646e-01,  5.2026e-01,  3.1855e-01, -1.3465e-02,\n          3.8804e-01,  6.3468e-01,  1.8269e-01, -2.0340e-01, -6.9265e-01,\n         -6.3195e-02,  1.8226e-01,  2.6223e-01, -1.7705e-01,  2.4969e-01,\n         -6.1951e-01, -3.8879e-01,  4.4354e-01, -4.6311e-01, -1.1856e-01,\n          3.2496e-01,  1.3757e-03,  3.5115e-01, -5.8269e-01, -4.2772e-01,\n         -3.7010e-01, -2.3305e-01,  1.7357e-01, -5.2408e-01,  2.5752e-02,\n         -4.0796e-01, -1.2127e-01, -6.9660e-03, -1.4113e-02, -1.6438e-01,\n         -1.7386e-01, -4.1619e-01,  2.4257e-01, -1.2855e-01, -2.1097e-01,\n          1.0538e-01, -9.4907e-02,  1.1744e-01, -2.8784e-01, -9.1079e-02,\n         -3.0805e-01, -3.3546e-01, -2.3906e-01, -6.3425e-02, -1.9235e-01,\n          2.7536e-01, -3.8934e-01, -4.2784e-03, -6.7160e-02,  1.2888e-01,\n         -2.2175e-01,  8.0395e-01,  1.1772e-02, -2.2516e-01, -5.1993e-01,\n          2.4821e-01, -4.6746e-02, -4.9723e-01, -1.4251e-01, -1.7620e-01,\n         -2.3458e-01,  3.9154e-01,  5.6724e-01,  4.9063e-01, -5.7849e-01,\n         -1.4932e-01,  5.9219e-01, -1.6256e-01,  5.2511e-01, -3.8263e-01,\n          3.0831e-02, -1.1377e-01,  8.9295e-02]], grad_fn=&lt;TanhBackward0&gt;), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)</pre>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "qFWw",
      "code_hash": "ba76835107a70231226f12a0702331b7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<pre style='font-size: 12px'>torch.Size([1, 20, 768])</pre>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "SGPb",
      "code_hash": "b10b143e226bfdf8873952e0e1e4c705",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"model-head\">Model Head\u4ed8\u304d\u3067\u547c\u3073\u51fa\u3059</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "mPdT",
      "code_hash": "34c9f102a35afe0e4c2e93538d742d98",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "zlDe",
      "code_hash": "1a48817363fac9504666230799f4911e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<pre style='font-size: 12px'>SequenceClassifierOutput(loss=None, logits=tensor([[ 7.9226, -0.9404,  0.2213, -1.6751, -1.5036, -0.6587, -0.1110,  0.2404,\n         -1.2336,  0.1111, -0.4822, -0.1233, -1.1580, -0.2003, -0.1709, -0.3932,\n         -0.1520, -0.2920, -0.6122, -0.4863]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</pre>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "aMWT",
      "code_hash": null,
      "outputs": [],
      "console": []
    },
    {
      "id": "YnzB",
      "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    }
  ]
}